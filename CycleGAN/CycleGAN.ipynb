{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsVSY4vMreM+QEajMhRZxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinishUchiha/GenerativeModeling/blob/master/CycleGAN/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ9giXdVjiij",
        "colab_type": "code",
        "outputId": "fc489666-2d32-4617-d8e1-9f09154ab8c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/monet2photo.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-02 10:23:53--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/monet2photo.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305231073 (291M) [application/zip]\n",
            "Saving to: ‘monet2photo.zip’\n",
            "\n",
            "monet2photo.zip     100%[===================>] 291.09M  20.6MB/s    in 15s     \n",
            "\n",
            "2020-06-02 10:24:09 (19.1 MB/s) - ‘monet2photo.zip’ saved [305231073/305231073]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu8W6euljuif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip monet2photo.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFpGEHRLj07d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from glob import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Conv2DTranspose, \\\n",
        "    ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.layers import InstanceNormalization\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import InstanceNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-zoDcxakm3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    res = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    res = BatchNormalization(axis=3, momentum=0.9, epsilon=1e-5)(res)\n",
        "    res = Activation('relu')(res)\n",
        "\n",
        "    res = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(res)\n",
        "    res = BatchNormalization(axis=3, momentum=0.9, epsilon=1e-5)(res)\n",
        "\n",
        "    return Add()([res, x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JC3e5aSldRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a generator network using the hyperparameter values defined below\n",
        "    \"\"\"\n",
        "    input_shape = (128, 128, 3)\n",
        "    residual_blocks = 6\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First Convolution block\n",
        "    x = Conv2D(filters=32, kernel_size=7, strides=1, padding=\"same\")(input_layer)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 2nd Convolution block\n",
        "    x = Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 3rd Convolution block\n",
        "    x = Conv2D(filters=128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(residual_blocks):\n",
        "        x = residual_block(x)\n",
        "\n",
        "    # Upsampling blocks\n",
        "\n",
        "    # 1st Upsampling block\n",
        "    x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 2nd Upsampling block\n",
        "    x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Last Convolution layer\n",
        "    x = Conv2D(filters=3, kernel_size=7, strides=1, padding=\"same\")(x)\n",
        "    output = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSMtKJabldOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a discriminator network using the hyperparameter values defined below\n",
        "    \"\"\"\n",
        "    input_shape = (128, 128, 3)\n",
        "    hidden_layers = 3\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(input_layer)\n",
        "\n",
        "    # 1st Convolutional block\n",
        "    x = Conv2D(filters=64, kernel_size=4, strides=2, padding=\"valid\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "\n",
        "    # 3 Hidden Convolution blocks\n",
        "    for i in range(1, hidden_layers + 1):\n",
        "        x = Conv2D(filters=2 ** i * 64, kernel_size=4, strides=2, padding=\"valid\")(x)\n",
        "        x = InstanceNormalization(axis=1)(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "\n",
        "    # Last Convolution layer\n",
        "    output = Conv2D(filters=1, kernel_size=4, strides=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcIN_GWmldKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images(data_dir):\n",
        "    imagesA = glob(data_dir + '/testA/*.*')\n",
        "    imagesB = glob(data_dir + '/testB/*.*')\n",
        "\n",
        "    allImagesA = []\n",
        "    allImagesB = []\n",
        "\n",
        "    for index, filename in enumerate(imagesA):\n",
        "        imgA = imread(filename, pilmode='RGB')\n",
        "        imgB = imread(imagesB[index], pilmode='RGB')\n",
        "\n",
        "        imgA = resize(imgA, (128, 128))\n",
        "        imgB = resize(imgB, (128, 128))\n",
        "\n",
        "        if np.random.random() > 0.5:\n",
        "            imgA = np.fliplr(imgA)\n",
        "            imgB = np.fliplr(imgB)\n",
        "\n",
        "        allImagesA.append(imgA)\n",
        "        allImagesB.append(imgB)\n",
        "\n",
        "    # Normalize images\n",
        "    allImagesA = np.array(allImagesA) / 127.5 - 1.\n",
        "    allImagesB = np.array(allImagesB) / 127.5 - 1.\n",
        "\n",
        "    return allImagesA, allImagesB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdc2pTQclcgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test_batch(data_dir, batch_size):\n",
        "    imagesA = glob(data_dir + '/testA/*.*')\n",
        "    imagesB = glob(data_dir + '/testB/*.*')\n",
        "\n",
        "    imagesA = np.random.choice(imagesA, batch_size)\n",
        "    imagesB = np.random.choice(imagesB, batch_size)\n",
        "\n",
        "    allA = []\n",
        "    allB = []\n",
        "\n",
        "    for i in range(len(imagesA)):\n",
        "        # Load images and resize images\n",
        "        imgA = resize(imread(imagesA[i], pilmode='RGB').astype(np.float32), (128, 128))\n",
        "        imgB = resize(imread(imagesB[i], pilmode='RGB').astype(np.float32), (128, 128))\n",
        "\n",
        "        allA.append(imgA)\n",
        "        allB.append(imgB)\n",
        "\n",
        "    return np.array(allA) / 127.5 - 1.0, np.array(allB) / 127.5 - 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q35ud60oluZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(originalA, generatedB, recosntructedA, originalB, generatedA, reconstructedB, path):\n",
        "    \"\"\"\n",
        "    Save images\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(2, 3, 1)\n",
        "    ax.imshow(originalA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 2)\n",
        "    ax.imshow(generatedB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 3)\n",
        "    ax.imshow(recosntructedA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 4)\n",
        "    ax.imshow(originalB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 5)\n",
        "    ax.imshow(generatedA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 6)\n",
        "    ax.imshow(reconstructedB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "\n",
        "    plt.savefig(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZAReNa-lyr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"monet2photo/\"\n",
        "batch_size = 1\n",
        "epochs = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Yc0lelmGoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagesA, imagesB = load_images(data_dir=data_dir)\n",
        "\n",
        "# Define the common optimizer\n",
        "common_optimizer = Adam(0.002, 0.5)\n",
        "\n",
        "# Build and compile generator networks\n",
        "discriminatorA = build_discriminator()\n",
        "discriminatorB = build_discriminator()\n",
        "\n",
        "discriminatorA.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "discriminatorB.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Build generator networks\n",
        "generatorAToB = build_generator()\n",
        "generatorBToA = build_generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H6JL4HomGjo",
        "colab_type": "code",
        "outputId": "145712f1-b10c-4b12-f6f1-19500b94302f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Create an adversarial network\n",
        "\n",
        "inputA = Input(shape=(128, 128, 3))\n",
        "inputB = Input(shape=(128, 128, 3))\n",
        "\n",
        "# Generated images using both of the generator networks\n",
        "generatedB = generatorAToB(inputA)\n",
        "generatedA = generatorBToA(inputB)\n",
        "\n",
        "# Reconstruct images back to original images\n",
        "reconstructedA = generatorBToA(generatedB)\n",
        "reconstructedB = generatorAToB(generatedA)\n",
        "\n",
        "generatedAId = generatorBToA(inputA)\n",
        "generatedBId = generatorAToB(inputB)\n",
        "\n",
        "# Make both of the discriminator networks non-trainable\n",
        "discriminatorA.trainable = False\n",
        "discriminatorB.trainable = False\n",
        "\n",
        "probsA = discriminatorA(generatedA)\n",
        "probsB = discriminatorB(generatedB)\n",
        "\n",
        "adversarial_model = Model(inputs=[inputA, inputB],\n",
        "                          outputs=[probsA, probsB, reconstructedA, reconstructedB,\n",
        "                                    generatedAId, generatedBId])\n",
        "adversarial_model.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n",
        "                          loss_weights=[1, 1, 10.0, 10.0, 1.0, 1.0],\n",
        "                          optimizer=common_optimizer)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()), write_images=True, write_grads=True,\n",
        "                          write_graph=True)\n",
        "tensorboard.set_model(generatorAToB)\n",
        "tensorboard.set_model(generatorBToA)\n",
        "tensorboard.set_model(discriminatorA)\n",
        "tensorboard.set_model(discriminatorB)\n",
        "\n",
        "real_labels = np.ones((batch_size, 7, 7, 1))\n",
        "fake_labels = np.zeros((batch_size, 7, 7, 1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-qNvFvimqLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "    dis_losses = []\n",
        "    gen_losses = []\n",
        "\n",
        "    num_batches = int(min(imagesA.shape[0], imagesB.shape[0]) / batch_size)\n",
        "    print(\"Number of batches:{}\".format(num_batches))\n",
        "\n",
        "    for index in range(num_batches):\n",
        "        print(\"Batch:{}\".format(index))\n",
        "\n",
        "        # Sample images\n",
        "        batchA = imagesA[index * batch_size:(index + 1) * batch_size]\n",
        "        batchB = imagesB[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "        # Translate images to opposite domain\n",
        "        generatedB = generatorAToB.predict(batchA)\n",
        "        generatedA = generatorBToA.predict(batchB)\n",
        "\n",
        "        # Train the discriminator A on real and fake images\n",
        "        dALoss1 = discriminatorA.train_on_batch(batchA, real_labels)\n",
        "        dALoss2 = discriminatorA.train_on_batch(generatedA, fake_labels)\n",
        "\n",
        "        # Train the discriminator B on ral and fake images\n",
        "        dBLoss1 = discriminatorB.train_on_batch(batchB, real_labels)\n",
        "        dbLoss2 = discriminatorB.train_on_batch(generatedB, fake_labels)\n",
        "\n",
        "        # Calculate the total discriminator loss\n",
        "        d_loss = 0.5 * np.add(0.5 * np.add(dALoss1, dALoss2), 0.5 * np.add(dBLoss1, dbLoss2))\n",
        "\n",
        "        print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "        \"\"\"\n",
        "        Train the generator networks\n",
        "        \"\"\"\n",
        "        g_loss = adversarial_model.train_on_batch([batchA, batchB],\n",
        "                                                  [real_labels, real_labels, batchA, batchB, batchA, batchB])\n",
        "\n",
        "        print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "        dis_losses.append(d_loss)\n",
        "        gen_losses.append(g_loss)\n",
        "\n",
        "    # Sample and save images after every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        # Get a batch of test data\n",
        "        batchA, batchB = load_test_batch(data_dir=data_dir, batch_size=2)\n",
        "\n",
        "        # Generate images\n",
        "        generatedB = generatorAToB.predict(batchA)\n",
        "        generatedA = generatorBToA.predict(batchB)\n",
        "\n",
        "        # Get reconstructed images\n",
        "        reconsA = generatorBToA.predict(generatedB)\n",
        "        reconsB = generatorAToB.predict(generatedA)\n",
        "\n",
        "        # Save original, generated and reconstructed images\n",
        "        for i in range(len(generatedA)):\n",
        "            save_images(originalA=batchA[i], generatedB=generatedB[i], recosntructedA=reconsA[i],\n",
        "                        originalB=batchB[i], generatedA=generatedA[i], reconstructedB=reconsB[i],\n",
        "                        path=\"results/gen_{}_{}\".format(epoch, i))\n",
        "\n",
        "# Save models\n",
        "generatorAToB.save_weights(\"generatorAToB.h5\")\n",
        "generatorBToA.save_weights(\"generatorBToA.h5\")\n",
        "discriminatorA.save_weights(\"discriminatorA.h5\")\n",
        "discriminatorB.save_weights(\"discriminatorB.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8HCaQCom8GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}